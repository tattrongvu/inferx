{
    "type": "function",
    "tenant": "t1",
    "namespace": "ns1",
    "name": "models--Qwen--Qwen2.5-7B",
    "spec": {
        "image": "vllm/vllm-openai:v0.6.2",
        "commands": [
            "--model",
            "Qwen/Qwen2.5-7B",
            "--enforce-eager",
            "--max-model-len",
            "2000",
            "--tensor-parallel-size=2"
        ],
        "resources": {
            "CPU": 6000,
            "Mem": 80000,
            "GPU": {
                "Type": "Any",
                "Count": 2,
                "vRam": 14000
            }
        },
        "envs": [
            [
                "LD_LIBRARY_PATH",
                "/usr/local/lib/python3.12/dist-packages/nvidia/cuda_nvrtc/lib/:$LD_LIBRARY_PATH"
            ]
        ],
        "mounts": [
            {
                "hostpath": "/home/brad/cache",
                "mountpath": "/root/.cache/huggingface"
            }
        ],
        "endpoint": {
            "path": "/v1/completions",
            "port": 8000,
            "schema": "Http"
        },
        "probe": {
            "path": "/health",
            "port": 8000,
            "schema": "Http"
        },
        "api_type": {
            "openai": {
                "name": "Qwen/Qwen2.5-7B",
                "max_tokens": 1000,
                "temperature": 0
            }
        }
    }
}